from fastapi import FastAPI, HTTPException, Body, Request
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Union
from opentelemetry import trace, metrics
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.sdk.metrics import Counter, MeterProvider
from opentelemetry.sdk.trace import TracerProvider

import os
import requests
import openai

# Configure OpenTelemetry
trace.set_tracer_provider(TracerProvider())
metrics.set_meter_provider(MeterProvider())

# Get the Tracer and Meter
tracer = trace.get_tracer("openai.tracer")
meter = metrics.get_meter("openai.meter")

# Create Counter instruments
tokens_counter = meter.create_counter(
    "tokens_counter",
    description="The number of tokens generated by model",
    unit="1",
)

prompt_tokens_counter = meter.create_counter(
    "prompt_tokens",
    description="The number of prompt tokens in a chat completion",
    unit="1",
)

completion_tokens_counter = meter.create_counter(
    "completion_tokens",
    description="The number of completion tokens in a chat completion",
    unit="1",
)

class Message(BaseModel):
    role: str = Field(..., example="system")
    content: Optional[str] = Field(None, example="You are a helpful assistant.")
    name: Optional[str] = Field(None, example="my_function")
    function_call: Optional[dict] = Field(None, example={"name": "my_function"})

class ChatCompletion(BaseModel):
    model: str = Field(..., example="gpt-3.5-turbo")
    messages: List[Message]
    temperature: Optional[float] = Field(None, example=0.5)
    max_tokens: Optional[int] = Field(None, example=100)

app = FastAPI()

@app.post("/openai/deployments/{deployment_id}/chat/completions")
async def create_chat_completion(deployment_id: str, chat_completion: ChatCompletion, request: Request, api_version: Optional[str] = "2023-05-15"):
    # Get the API key from the request headers
    api_key = request.headers.get('openai-api-key')

    # Partially mask the API key for privacy
    if api_key:
        api_key = api_key[:3] + '...' + api_key[-4:]
    else: 
        api_key = "None"
    
    with tracer.start_as_current_span("openai_chat_completion"):
        response = openai.ChatCompletion.create(
            model=chat_completion.model,
            messages=[message.dict(exclude_none=True) for message in chat_completion.messages],
            temperature=chat_completion.temperature,
            max_tokens=chat_completion.max_tokens
        )

        attributes = {"model": chat_completion.model, "chat_completion_id": response['id'], "api_key": api_key}
        # Increment the counter for the number of tokens generated
        # Add the API key to the metrics labels
        tokens_counter.add(response['usage']['total_tokens'], attributes)

        # Record the prompt and completion tokens
        # Add the chat completion ID to the metrics labels
        prompt_tokens_counter.add(response['usage']['prompt_tokens'], attributes)
        completion_tokens_counter.add(response['usage']['completion_tokens'], attributes)
    
    return response

FastAPIInstrumentor.instrument_app(app)